## 网络

### HTTP

---

#### 状态码

---

##### 2xx

1. 200OK，响应头有body数据；
2. 204 No content 响应头无数据；
3. 206 Partial content 分块下载和断点续传，部分数据。

##### 3xx

1. 301 永久重定向，资源不在（Location，定向地址）
2. 302 临时重定向，资源还在，暂时需要重定向（Location）
3. 304 表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

##### 4xx

1. 400 错误请求，请求报文有问题；
2. 403 **Forbidden** 服务器禁止访问，非请求出错；
3. 404 Not Found 请求资源不存在和未找到，无法提供。

##### 5xx

1. 500 **Internal Server Error **服务器发生了什么错误;
2. 501 No implemented 表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
3. 502 Bad Gateway 服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
4. 503 **Service Unavailable **表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

---

#### 常见字段

---

##### Host

客户端发送请求时，用来指定服务器的域名。

##### *Content-Length*

服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。用于解决“粘包”问题。body长度，回车换行分割header。

##### *Connection*

常用于**客户端要求服务器使用「HTTP 长连接」机制**，以便其他请求复用。**HTTP/1.1 版本的默认连接都是长连接**，但为了兼容老版本的 HTTP，需要指定 `Connection` 首部字段的值为 `Keep-Alive`。

##### *Content-Type*

告诉客户端，本次数据是什么格式。

**客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式**。

##### *Content-Encoding*

说明**数据的压缩**方法。表示服务器返回的数据使用了什么压缩格式。**客户端在请求时，用 `Accept-Encoding` 字段**说明自己可以接受哪些压缩方法。

---

#### Get and Post

---

##### Get

GET 的语义是从服务器**获取指定的资源**

请求的参数位置一般是写在 URL 中，**URL 规定只能支持 ASCII**，所以 GET 请求的参数只允许 ASCII 字符 ，而且**浏览器会对 URL 的长度有限制**（HTTP协议本身对 URL长度并没有做任何规定）。

##### Post

POST 的语义是**根据请求负荷（报文body）**对指定的资源**做出处理**。

写在报文 body 中，body 中的数据可以是**任意格式的数据**，只要客户端与服务端协商好即可，而且**浏览器不会对 body 大小做限制**。

##### 强制性？

RFC 规范并**没有规定 GET 请求不能带 body 的**。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。

另外，**URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的**。

---

##### 安全和幂等

安全是指请求方法不会**「破坏」服务器上的资源**；多次执行**相同的操作，结果都是「相同」的**。

1. GET：只读——安全，安全——幂等。
2. Post：新增或提交数据进行处理——非安全，多次操作——资源不同所以非幂等。
3. **浏览器是不会缓存POST请求，也不能作为书签**。

---

#### HTTP缓存

##### 强制缓存

强缓存指的是**只要浏览器判断**缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的**主动性在于浏览器**这边。

HTTP 响应头部（Response Header）字段：

1. Cache-Control：一个相对时间；
2. Expires：一个绝对时间；

**Cache-Control 的优先级高于 Expires**，浏览器第一次请求访问服务器资源，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；再次请求访问服务器，**与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，没有，则使用该缓存，否则重新请求服务器（服务器**再次收到请求后，会再次更新** Response 头部的 Cache-Control。）；

##### 协商缓存

通过**服务端告知客户端**是否可以使用缓存的方式被称为协商缓存。304 缓存重定向。

1. 请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified`（最后**修改时间**） 字段实现；资源过期会发送带有 `If-Modified-Since`的请求，服务器检测Last-Modified判断修改时间大小，如果没有最新修改，则返回304，否则返回最新资源，200OK。
2. 请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag`（**唯一标识响应资源**） 字段，当资源过期时，浏览器发现响应头里有 **Etag（优先级高于Last-Modified）**，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。

**Tips：协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。

---

#### HTTP 特性

HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。

##### 简单

HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。

##### 灵活和易扩展

HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。

同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**，比如：

- HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；
- HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

##### 应用广泛和跨平台

互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有**跨平台**的优越性。

#### 缺点有哪些？

HTTP 协议里有优缺点一体的**双刃剑**，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。

##### 无状态

**好处**：服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能**减轻服务器的负担**，能够把更多的 CPU 和内存用来对外提供服务。

无状态的**坏处**，既然服务器没有记忆能力，它在完成有**关联性的操作时会非常麻烦**。

cookies解决关联性如认证等问题请求，响应（cookies），请求（cookies），验证，响应。

##### 明文传输

##### 不安全

- 通信使用明文（不加密），内容可能会被窃听。比如，**账号信息容易泄漏，那你号没了。**
- 不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多，那你钱没了。**
- 无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告，视觉污染，眼没了。**

---

### Http 1.1/2/3演化

#### HTTP 1.1

##### **优点：**

1. 使用长连接替代短链接，减少连接创建的**开销**
2. 使用管道降低整体数据传输的**响应**时间

##### 缺点：

1. 请求/响应头部**没有压缩，导致延迟较大**；
2. 发送**相同冗长的头部造成浪费**；
3. **服务器队头阻塞**；
4. 没有请求**优先级控制**；
5. **只能从客户端开始**，服务器只能被动响应。

#### HTTP 2

相比 HTTP/1.1 性能上的改进：

* 头部压缩（减少延迟和浪费）
* 二进制格式
* 并发传输
* 服务器主动推送资源

##### **压缩：**

同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你 **消除重复的部分** 。

客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就**不发送同样字段了，只发送索引号**，这样就**提高速度**了。

##### 二进制格式**：**

不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了 **二进制格式** ，头信息和数据体都是二进制，并且统称为帧（frame）： **头信息帧（Headers Frame）和数据帧（Data Frame）** 。

收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这 **增加了数据传输的效率** 。字符200 OK 需要3个字节表示，在HTTP 2 的二进制下只需要1个字节，1000 1000（第一个1为处于静态表中，后7位为编码，200是8）。

##### **并发传输：** 

引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。解决了基于请求-响应模型的队头阻塞。

**针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应** 。

##### **服务器推送：**

客户端和服务器 双方都可以建立 Stream ， Stream ID 也是有区别的， **客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。** 在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。 在HTTP 1.1 只能客户端请求CSS。

##### **缺点：**

HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是**在 TCP 这一层**。

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。**

一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的 **所有的 HTTP 请求都必须等待这个丢了的包被重传回来** 。

---


#### HTTP/3

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

##### 无队头阻塞

可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。

**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

##### 更快的连接建立

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

##### 连接迁移

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程**包含 TCP 三次握手和 TLS 四次握手的时延**，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。

HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。

---

### HTTP/1.1 优化

- *尽量避免发送 HTTP 请求*；
- *在需要发送 HTTP 请求时，考虑如何减少请求次数*；
- *减少服务器的 HTTP 响应的数据大小*；

---

#### 避免发送HTTP请求

使用缓存，关于缓存（协商缓存与强制缓存）。

强制缓存指的是当响应数据在本地缓存中没过期（时间由服务器估算），浏览器强制使用缓存。

协商缓存是指过期，需要判断响应数据改没改，1. 通过Last-Modified判断是否大于等于最后修改时间；2. 通过Etag，计算数据hash值比对一致性。当没修改则返回304，否则200 OK。

---

#### 减少HTTP请求次数

- *减少重定向请求次数*；
- *合并请求*；
- *延迟发送请求*；

##### 减少重定向请求次数

重定向的工作**交由代理服务器**完成，就能减少 HTTP 请求次数了，当代理服务器知晓了重定向规则（无需请求源服务器）后，可以进一步减少消息传递次数。

301 永久重定向，302 临时重定向，303 重定向到其它资源，307与302相似，但是不得改变请求方法，308与301相似，不得改变请求方法。

**301/308响应码是告诉客户端可以将重定向响应缓存到本地磁盘**，之后客户端就自动用 url2 替代 url1 访问服务器的资源。

##### 合并请求

**合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求**。

**减少了重复发送的 HTTP 头部**。

但是这样的合并请求会带来新的问题，**当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件**，这显然带来了额外的网络消耗。

由于 HTTP/1.1 是请求响应模型，如果第一个发送的请求，未收到对应的响应，那么后续的请求就不会发送（PS：HTTP/1.1 管道模式是默认不使用的，所以讨论 HTTP/1.1 的队头阻塞问题，是不考虑管道模式的），于是为了防止单个请求的阻塞，所以**一般浏览器会同时发起 5-6 个请求，每一个请求都是不同的 TCP 连接**，那么如果合并了请求，也就会**减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间**。

##### 延迟发送请求

一个HTML中包含多个HTTP请求，类似于懒加载和缺页中断，只有到使用了在请求这些HTTP。

---

#### 减少HTTP响应数据的大小

压缩的方式一般分为 2 种，分别是：

- *无损压缩*；
- *有损压缩*；

##### 无损压缩

无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码。

首先，我们针对代码的语法规则进行压缩，因为**通常代码文件都有很多换行符或者空格**，这些是为了帮助程序员更好的阅读，但是机器执行时并不要这些符，把这些多余的符号给去除掉。

接下来，就是无损压缩了，需要对原始资源建立统计模型，利用这个统计模型，**将常出现的数据用较短的二进制比特序列表示，将不常出现的数据用较长的二进制比特序列表示，生成二进制比特序列一般是「霍夫曼编码」算法。**

gzip 就是比较常见的无损压缩。客户端支持的压缩算法，会在 HTTP 请求中通过头部中的 `Accept-Encoding` 字段告诉服务器（**多个**）。

服务器通过响应头部中的 `Content-Encoding` 字段告诉客户端该资源使用的压缩算法。

##### 有损压缩

有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如音频、视频、图片。

可以通过 HTTP 请求头部中的 `Accept` 字段里的「 q 质量因子」，告诉服务器期望的资源质量。

---

### HTTPS RSA

#### TLS握手

**4次握手：**

1. client hello：发送随机数，TSL版本，加密套件列表（RSA，ECDHE等）；
2. server hello：服务器随机数，选择加密套件，确认版本，证书，server hello done；
3. Client key Exchange，Change Cipher Spec（后续加密进行交流），Encrypted HansShake Message（前面数据的摘要）；
4. Change Cipher Spec，Encrypted HandShake Message。

#### ECDHE

区别在于选择ECDHE密钥协商算法。在发送完证书后，发送「**Server Key Exchange**」消息。

这时服务器做了三件事：

- 选择了**名为 x25519 的椭圆曲线**，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；
- 生成**随机数作为服务端椭圆曲线的私钥**，保留到本地；
- 根据基点 G 和私钥计算出**服务端的椭圆曲线公钥**，这个会公开给客户端。

随后，就是「**Server Hello Done**」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。

客户端校验证书合法，客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成**客户端的椭圆曲线公钥**，然后用「**Client Key Exchange**」消息发给服务端。

双方都就计算出点（x，y），其中 **x 坐标值（ECDHE 算法算出的共享密钥）**双方都是一样的。

**最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的**。

#### RSA 和 ECDHE 握手过程的区别：

- RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；
- 使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，**而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据**，节省了一个消息的往返时间（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）；
- 使用 ECDHE， 在 TLS 第 2 次握手中，**会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息**；

---

### HTTPS 优化

产生性能消耗的两个环节：

- 第一个环节， TLS 协议**握手**过程；
- 第二个环节，握手后的对称**加密**报文传输。

#### 握手

- 对于 ECDHE 密钥协商算法，握手过程中会**客户端和服务端都需要临时生成椭圆曲线公私钥**；
- 客户端**验证证书**时，会访问 CA 获取 CRL 或者 OCSP，目的是**验证服务器的证书是否有被吊销**；
- 双方**计算 Pre-Master**，也就是对称加密密钥；

#### 硬件优化

选择可以**支持 AES-NI 特性的 CPU**，加速了使用AES加密的过程。并且HTTPS是密集型的，使用更好的CPU能够提升速度。

#### 软件优化

##### 软件升级

软件升级就是将正在使用的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。

##### 协议优化

对「密钥交换过程」进行优化。

**RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高**。

因此如果可以，尽量**选用 ECDHE 密钥交换**算法替换 RSA 算法，因为该算法由于支持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 **TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性**。

ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽量**选择 x25519 曲线**，该曲线是目前最快的椭圆曲线。

**对称加密算法方面**，如果对安全性不是特别高的要求，可以**选用 AES_128_GCM**，它比 AES_256_GCM 快一些，因为密钥的长度短一些。

**TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手**。

怎么合并的呢？具体的做法是，客户端在 **Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。**

服务端收到后，**选定一个椭圆曲线**等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是**客户端计算出会话密钥**，就可以进行应用数据的加密传输了。

而且，TLS1.3 对密码套件进行“减肥”了， **对于密钥交换算法，废除了不支持前向安全性的 RSA 和 DH 算法，只支持 ECDHE 算法**。

#### 证书优化

两个方向：

- 一个是**证书传输**，
- 一个是**证书验证**；

##### 证书传输

**选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC 密钥长度比 RSA 短的多**。

##### 证书验证

客户端在验证证书时，是个复杂的过程，会走证书链逐级验证，验证的过程不仅需要**「用 CA 公钥解密证书」以及「用签名算法验证证书的完整性」**，而且为了知道证书是否被 CA 吊销，客户端有时还会**再去访问 CA， 下载 CRL 或者 OCSP 数据，以此确认证书的有效性**。

这个访问过程是 HTTP 访问，因此又会产生一系列网络通信的开销，如 DNS 查询、建立连接、收发数据等。

CRL 称为证书吊销列表（*Certificate Revocation List*），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。

​	存在两个问题：

- 第一个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果一个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，**实时性较差**；
- 第二个问题，**随着吊销证书的增多，列表会越来越大，下载的速度就会越慢**，下载完客户端还得遍历这么大的列表，那么就会导致客户端在校验证书这一环节的延时很大，进而拖慢了 HTTPS 连接。

现在基本都是使用 OCSP ，名为在线证书状态协议（*Online Certificate Status Protocol*）来查询证书的有效性，它的工作方式是**向 CA 发送查询请求，让 CA 返回证书的有效状态**。

OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它。

当有客户端发起连接请求时，服务器会把这个「响应结果」在 TLS 握手过程中发给客户端。由于有签名的存在，服务器无法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。

#### 会话复用

会话复用分两种：

- 第一种叫 Session ID；
- 第二种叫 Session Ticket；

##### Session ID

**客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识**，Session ID 和会话密钥相当于 key-value 的关系。

当客户端再次连接时，hello 消息里会带上 Session ID，服务器收到后就会从内存找，如果找到就直接用该会话密钥恢复会话状态，跳过其余的过程，只用一个消息往返就可以建立安全通信。当然**为了安全性，内存中的会话密钥会定期失效。**

​	两个缺点：

- 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，**服务器的内存压力也会越大**。
- 现在网站服务一般是由多台服务器通过负载均衡提供服务的，**客户端再次连接不一定会命中上次访问过的服务器**，于是还要走完整的 TLS 握手过程；

##### Session Ticket

**服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端**，类似于 HTTP 的 Cookie。

客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。

客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。

Session ID 和 Session Ticket **都不具备前向安全性**，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。

避免重放攻击的方式就是需要**对会话密钥设定一个合理的过期时间**。

前面的 Session ID 和 Session Ticket 方式都需要在 1 RTT 才能恢复会话。

##### Pre-shared Key

而 TLS1.3 更为牛逼，对于重连 TLS1.3 只需要 **0 RTT**，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 **Pre-shared Key**。







---

### TCP

---

#### TCP 基本认识

---

##### TCP 头格式有哪些？

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

**控制位：**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中**出现异常必须强制断开连接**。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接**。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段**。

---

##### TCP 是啥

- **面向连接**：一定是**「一对一」**才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以**保证一个报文一定能够到达接收端**；
- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果**不知道「消息的边界」，是无法读出一个有效的用户消息的**。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使**它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃**。

---

##### TCP 连接

**用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。**

建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。

- **Socket**：由 IP 地址和端口号组成
- **序列号**：用来解决乱序问题等
- **窗口大小**：用来做流量控制

---

##### 唯一确定一个 TCP 连接

TCP 四元组可以唯一的确定一个连接，四元组包括如下：

- 源地址
- 源端口
- 目的地址
- 目的端口

有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzExLmpwZw?x-oss-process=image/format,png)

受以下因素影响：

- **文件描述符限制**，**每个 TCP 连接都是一个文件**，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：
  - **系统级**：当前系统可打开的最大数量，通过 `cat /proc/sys/fs/file-max` 查看；
  - **用户级**：指定用户可打开的最大数量，通过 `cat /etc/security/limits.conf` 查看；
  - **进程级**：单个进程可打开的最大数量，通过 `cat /proc/sys/fs/nr_open` 查看；
- **内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。

---

##### UDP 和 TCP 有什么区别呢？分别的应用场景是？

**TCP 和 UDP 区别：**

*1. 连接*

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

*3. 可靠性*

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 **QUIC 协议**，具体可以参见这篇文章：[如何基于 UDP 协议实现可靠传输？(opens new window)](https://xiaolincoding.com/network/3_tcp/quic.html)

*4. 拥塞控制、流量控制*

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

*5. 首部开销*

- TCP 首部长度较长，会有一定的开销，首部在没有**使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的**。
- **UDP 首部只有 8 个字节**，并且是固定不变的，开销较小。

*6. 传输方式*

- TCP 是**流式传输，没有边界**，但保证顺序和可靠。
- UDP 是**一个包一个包**的发送，是有边界的，但可能会丢包和乱序。

*7. 分片不同*

- TCP 的数据大小如果**大于 MSS 大小，则会在传输层进行分片**，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果**大于 MTU 大小，则会在 IP 层进行分片**，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

> 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？

原因是 TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录 UDP 的首部长度。

> 为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？

IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。

-----

##### TCP 和 UDP 可以使用同一个端口吗？

**可以的**。

传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

TCP 和 UDP，在内核中是**两个完全独立的软件模块**。

因此，TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。

----

#### TCP 建立

